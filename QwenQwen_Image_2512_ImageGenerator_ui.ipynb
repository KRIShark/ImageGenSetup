{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577aa221-70e3-4793-91cc-6ee3357c1115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "[INFO] Gradio version: 6.2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5748195f9cc47c9b55f99d8306ce4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42e755d8bf1466a971f38e4993345c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3d8dc432fc44208e134cdd1097bc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://279259b4bbfc9de12c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://279259b4bbfc9de12c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6692acdff9f9484ebc8608e1a74b7874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad28d921e89248aaab0b1a70922218f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import torch\n",
    "import gradio as gr\n",
    "from diffusers import QwenImagePipeline\n",
    "from packaging import version\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Device & dtype\n",
    "# =====================================================\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    torch_dtype = torch.float32\n",
    "\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "print(f\"[INFO] Gradio version: {gr.__version__}\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Load Qwen Image pipeline (ONCE)\n",
    "# IMPORTANT: with device_map, DO NOT call pipe.to(...)\n",
    "# =====================================================\n",
    "pipe = QwenImagePipeline.from_pretrained(\n",
    "    \".././qwen_image_get_model/Qwen-Image-2512\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    device_map=\"balanced\",\n",
    "    max_memory={\n",
    "        0: \"80GiB\",\n",
    "        \"cpu\": \"120GiB\"\n",
    "    },\n",
    "    low_cpu_mem_usage=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "# Optional (runtime memory helpers)\n",
    "# pipe.enable_attention_slicing()\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Aspect ratios\n",
    "# =====================================================\n",
    "ASPECT_RATIOS = {\n",
    "    \"1:1\": (1328, 1328),\n",
    "    \"16:9\": (1664, 928),\n",
    "    \"9:16\": (928, 1664),\n",
    "    \"4:3\": (1472, 1104),\n",
    "    \"3:4\": (1104, 1472),\n",
    "    \"3:2\": (1584, 1056),\n",
    "    \"2:3\": (1056, 1584),\n",
    "}\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Generation function\n",
    "# =====================================================\n",
    "def generate_image(prompt, negative_prompt, aspect_ratio, steps, cfg_scale, seed):\n",
    "    width, height = ASPECT_RATIOS[aspect_ratio]\n",
    "\n",
    "    gen_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    generator = torch.Generator(device=gen_device)\n",
    "\n",
    "    seed = int(seed)\n",
    "    if seed >= 0:\n",
    "        generator.manual_seed(seed)\n",
    "    else:\n",
    "        generator = None  # random\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        out = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            num_inference_steps=int(steps),\n",
    "            true_cfg_scale=float(cfg_scale),\n",
    "            generator=generator,\n",
    "        )\n",
    "\n",
    "    return out.images[0]\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Gradio UI\n",
    "# =====================================================\n",
    "with gr.Blocks(title=\"Qwen Image Generator\") as demo:\n",
    "    gr.Markdown(\"## Qwen Image Generator (Diffusers)\")\n",
    "    gr.Markdown(f\"**Device:** `{device}`\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            prompt = gr.Textbox(\n",
    "                lines=8,\n",
    "                label=\"Prompt\",\n",
    "                value=(\n",
    "                    \"A 20-year-old East Asian girl with delicate, charming features and \"\n",
    "                    \"large, bright brown eyes—expressive and lively, with a cheerful or subtly smiling expression. \"\n",
    "                    \"Her naturally wavy long hair is either loose or tied in twin ponytails. \"\n",
    "                    \"She has fair skin and light makeup accentuating her youthful freshness. \"\n",
    "                    \"She wears a modern, cute dress or relaxed outfit in bright, soft colors. \"\n",
    "                    \"She stands indoors at an anime convention, casual iPhone snapshot.\"\n",
    "                ),\n",
    "            )\n",
    "            negative_prompt = gr.Textbox(\n",
    "                lines=4,\n",
    "                label=\"Negative Prompt\",\n",
    "                value=\"低分辨率，低画质，肢体畸形，手指畸形，画面过饱和，蜡像感，人脸无细节，过度光滑，画面具有AI感。构图混乱。文字模糊，扭曲。\",\n",
    "            )\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            aspect_ratio = gr.Dropdown(list(ASPECT_RATIOS.keys()), value=\"16:9\", label=\"Aspect Ratio\")\n",
    "            steps = gr.Slider(5, 50, value=10, step=1, label=\"Inference Steps\")\n",
    "            cfg = gr.Slider(1.0, 8.0, value=4.0, step=0.1, label=\"CFG Scale\")\n",
    "            seed = gr.Number(value=42, precision=0, label=\"Seed (-1 = random)\")\n",
    "            generate = gr.Button(\"Generate\")\n",
    "\n",
    "    output = gr.Image(label=\"Generated Image\", type=\"pil\")\n",
    "\n",
    "    generate.click(\n",
    "        fn=generate_image,\n",
    "        inputs=[prompt, negative_prompt, aspect_ratio, steps, cfg, seed],\n",
    "        outputs=output,\n",
    "    )\n",
    "\n",
    "# =====================================================\n",
    "# Queue (version-safe)\n",
    "# =====================================================\n",
    "try:\n",
    "    # Gradio 4.x\n",
    "    if version.parse(gr.__version__) >= version.parse(\"4.0.0\"):\n",
    "        demo.queue(default_concurrency_limit=1)\n",
    "    else:\n",
    "        # Gradio 3.x\n",
    "        demo.queue(concurrency_count=1)\n",
    "except TypeError:\n",
    "    # Fallback for versions that accept no args\n",
    "    demo.queue()\n",
    "\n",
    "# Launch\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d59bd-3947-4f65-a524-e3ee9ca10d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
